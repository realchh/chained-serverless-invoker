{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96513a9",
   "metadata": {},
   "source": [
    "Yes. Import the model and call predict directly:\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from serverless_tuner_middleware.model import fit_regression_model, REGRESSION_MODEL\n",
    "\n",
    "# Use the pre-fit default model\n",
    "lat_ms = REGRESSION_MODEL.predict(\n",
    "    \"http\", \"ea1->ea1\", \"p50\", payload_bytes=10*1024, rate_rps=1.0\n",
    ")\n",
    "\n",
    "# Or fit from a custom CSV directory, then predict\n",
    "m = fit_regression_model(Path(\"middleware/serverless_tuner_middleware/csv\"))\n",
    "lat_ms = m.predict(\"pubsub\", \"ea1->we1\", \"p90\", payload_bytes=200*1024, rate_rps=2.0)\n",
    "print(lat_ms)\n",
    "```\n",
    "\n",
    "Unified form with a flexible rate term: lat_q = c_floor_q + a_q / (k_q + rate_rps) + d_rate_q * rate_rps + b_size_q * payload_bytes. Constrain a_q, k_q, b_size_q ≥ 0, but let d_rate_q be signed so HTTP can slope slightly up while Pub/Sub gets the 1/(k+rate) benefit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80689f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pubsub', 'us-east1->us-east1', 'p50') Coeffs(a_inv_rate=5.865408051228487, b_size=2.989880066140614e-05, c_floor=2.1252062873468986, d_rate=7.627377713099122, k_shift=0.01)\n",
      "('http', 'us-east1->us-west1', 'p50') Coeffs(a_inv_rate=10.405549002836011, b_size=0.0004141352149209306, c_floor=4.942788426033644, d_rate=19.523151576519012, k_shift=0.01)\n",
      "('pubsub', 'us-east1->us-west1', 'p50') Coeffs(a_inv_rate=10.947183770090419, b_size=0.00045125855403260756, c_floor=3.8441811528053904, d_rate=13.610772460699081, k_shift=0.01)\n",
      "('http', 'us-east1->us-east1', 'p50') Coeffs(a_inv_rate=6.187576644196875, b_size=7.969001825315003e-06, c_floor=2.901354688456081, d_rate=11.41594912391156, k_shift=0.01)\n",
      "('pubsub', 'us-east1->us-east1', 'p90') Coeffs(a_inv_rate=8.842123539015311, b_size=3.260264670580748e-05, c_floor=3.4713737289580138, d_rate=12.865825617685914, k_shift=0.01)\n",
      "('http', 'us-east1->us-west1', 'p90') Coeffs(a_inv_rate=11.621247962360798, b_size=0.00044946679383717637, c_floor=5.581350865214176, d_rate=22.11623403429985, k_shift=0.01)\n",
      "('pubsub', 'us-east1->us-west1', 'p90') Coeffs(a_inv_rate=24.071266517797433, b_size=0.00028530553666592163, c_floor=19.06309531429963, d_rate=84.14674374461174, k_shift=0.01)\n",
      "('http', 'us-east1->us-east1', 'p90') Coeffs(a_inv_rate=6.667098960559491, b_size=1.634076219233236e-05, c_floor=3.2395782407463116, d_rate=12.880006394349039, k_shift=0.01)\n",
      "('pubsub', 'us-east1->us-east1', 'p99') Coeffs(a_inv_rate=68.89037193470563, b_size=0.0, c_floor=689.9026663359687, d_rate=-19.36109175013553, k_shift=10.0)\n",
      "('http', 'us-east1->us-west1', 'p99') Coeffs(a_inv_rate=32.2705364269532, b_size=6.353241076134914e-05, c_floor=37.775511936350085, d_rate=175.24857184290886, k_shift=0.01)\n",
      "('pubsub', 'us-east1->us-west1', 'p99') Coeffs(a_inv_rate=88.75690278572284, b_size=0.00017305035748285065, c_floor=31.35616158964808, d_rate=111.3160570114851, k_shift=0.01)\n",
      "('http', 'us-east1->us-east1', 'p99') Coeffs(a_inv_rate=20.03404224431688, b_size=0.0, c_floor=204.65919631144496, d_rate=55.196463462139945, k_shift=10.0)\n"
     ]
    }
   ],
   "source": [
    "from middleware.serverless_tuner_middleware.model import REGRESSION_MODEL\n",
    "for k,v in REGRESSION_MODEL.coeffs.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899b5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_key | payload_avg/min/max (B) | rate_rps | observed_p50_ms | model_p50_http | model_p50_pubsub\n",
      "get_input:entry_point:0->text_2_speech:get_input_0_0:1 | 16009.866310160427 / 16009 / 16010 | 0.0404 | 133.0 | 126.37076332236076 | 119.39477009206409\n",
      "get_input:entry_point:0->profanity:get_input_0_1:2 | 15997.862637362638 / 15997 / 15998 | 0.0393 | 129.0 | 129.04899532778677 | 121.93673269973729\n",
      "text_2_speech:get_input_0_0:1->encoding:text_2_speech_1_0:3 | 16012.853846153846 / 16012 / 16013 | 0.0332 | 70.0 | 146.5787659034145 | 138.57346270852946\n",
      "profanity:get_input_0_1:2->censor:sync: | 15864.852713178294 / 15864 / 15865 | 0.0330 | 71.0 | 147.16370457882283 | 139.1252031017226\n",
      "encoding:text_2_speech_1_0:3->censor:sync: | None / None / None | 0.0000 | None | None | None\n",
      "\n",
      "node runtimes (p50):\n",
      "encoding: p50=1599.0 ms count=75\n",
      "text_2_speech: p50=7180.0 ms count=84\n",
      "profanity: p50=41751.0 ms count=9\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "from middleware.serverless_tuner_middleware.stats import (\n",
    "    compute_edge_samples, aggregate_edge_stats,\n",
    "    compute_node_samples, aggregate_node_stats,\n",
    ")\n",
    "from middleware.serverless_tuner_middleware.critical_path import edge_key\n",
    "from middleware.serverless_tuner_middleware.rewrite import _infer_region_pair\n",
    "from middleware.serverless_tuner_middleware.model import REGRESSION_MODEL\n",
    "from middleware.serverless_tuner_middleware.config import load_config\n",
    "\n",
    "LOGS = Path(\"results/tts/logs.ndjson\")\n",
    "CFG = load_config(\"results/tts/invoker_config.ndjson\")\n",
    "\n",
    "with LOGS.open() as f:\n",
    "    sends, recvs = parse_events_from_lines(f)\n",
    "\n",
    "edge_stats = aggregate_edge_stats(compute_edge_samples(sends, recvs))\n",
    "node_stats = aggregate_node_stats(compute_node_samples(sends, recvs))\n",
    "\n",
    "payloads = defaultdict(list)\n",
    "ts_map = defaultdict(list)\n",
    "for s in sends:\n",
    "    payloads[edge_key(s)].append(s.payload_size)\n",
    "    ts_map[edge_key(s)].append(s.ts_ms)\n",
    "\n",
    "rates = {}\n",
    "for ek, ts in ts_map.items():\n",
    "    dur = (max(ts) - min(ts)) / 1000 if len(ts) > 1 else 0\n",
    "    rates[ek] = len(ts) / dur if dur > 0 else 0.0\n",
    "\n",
    "print(\"edge_key | payload_avg/min/max (B) | rate_rps | observed_p50_ms | model_p50_http | model_p50_pubsub\")\n",
    "for e in CFG.edges:\n",
    "    ek = edge_key(e)\n",
    "    region = _infer_region_pair(e)\n",
    "    obs = edge_stats.get((ek, \"http\")) or edge_stats.get((ek, \"pubsub\"))\n",
    "    obs_p50 = obs.p50 if obs else None\n",
    "\n",
    "    sizes = payloads.get(ek, [])\n",
    "    avg_payload = sum(sizes) / len(sizes) if sizes else None\n",
    "    min_payload = min(sizes) if sizes else None\n",
    "    max_payload = max(sizes) if sizes else None\n",
    "    rate = rates.get(ek, 0.0)\n",
    "\n",
    "    http_pred = pubsub_pred = None\n",
    "    if region and avg_payload is not None:\n",
    "        http_pred = REGRESSION_MODEL.predict(\"http\", region, \"p50\", payload_bytes=avg_payload, rate_rps=rate)\n",
    "        pubsub_pred = REGRESSION_MODEL.predict(\"pubsub\", region, \"p50\", payload_bytes=avg_payload, rate_rps=rate)\n",
    "\n",
    "    print(f\"{ek} | {avg_payload} / {min_payload} / {max_payload} | {rate:.4f} | {obs_p50} | {http_pred} | {pubsub_pred}\")\n",
    "\n",
    "print(\"\\nnode runtimes (p50):\")\n",
    "for fn, stat in node_stats.items():\n",
    "    print(f\"{fn}: p50={stat.p50} ms count={stat.count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad8051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profanity: recvs=156, sends=22, missing_runtime=147\n",
      "text_2_speech: recvs=154, sends=130, missing_runtime=70\n",
      "censor: recvs=121, sends=0, missing_runtime=121\n",
      "encoding: recvs=87, sends=107, missing_runtime=12\n",
      "\n",
      "Edge send counts:\n",
      "get_input:entry_point:0->text_2_speech:get_input_0_0:1 187\n",
      "get_input:entry_point:0->profanity:get_input_0_1:2 182\n",
      "profanity:get_input_0_1:2->censor:sync: 129\n",
      "text_2_speech:get_input_0_0:1->encoding:text_2_speech_1_0:3 130\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "\n",
    "with Path(\"results/tts/logs.ndjson\").open() as f:\n",
    "    sends, recvs = parse_events_from_lines(f)\n",
    "\n",
    "recvs_by_fn = defaultdict(set)\n",
    "sends_by_fn = defaultdict(set)\n",
    "for r in recvs:\n",
    "    recvs_by_fn[r.fn_name].add(r.run_id)   # run_id only\n",
    "for s in sends:\n",
    "    sends_by_fn[s.from_fn].add(s.run_id)   # run_id only\n",
    "\n",
    "for fn in recvs_by_fn:\n",
    "    missing = recvs_by_fn[fn] - sends_by_fn[fn]\n",
    "    print(f\"{fn}: recvs={len(recvs_by_fn[fn])}, sends={len(sends_by_fn[fn])}, missing_runtime={len(missing)}\")\n",
    "\n",
    "\n",
    "# Edge sample counts\n",
    "edge_counts = defaultdict(int)\n",
    "for s in sends:\n",
    "    edge_counts[edge_key(s)] += 1\n",
    "print(\"\\nEdge send counts:\")\n",
    "for ek, cnt in edge_counts.items():\n",
    "    print(ek, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7e73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched sends->recvs: 21\n",
      "total sends: 22 total recvs: 121\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "from middleware.serverless_tuner_middleware.critical_path import edge_key\n",
    "\n",
    "with Path(\"results/tts/logs.ndjson\").open() as f:\n",
    "    sends, recvs = parse_events_from_lines(f)\n",
    "\n",
    "send_pairs = Counter((s.run_id, s.taint, s.to_fn) for s in sends if s.from_fn==\"profanity\")\n",
    "recv_pairs = Counter((r.run_id, r.taint, r.fn_name) for r in recvs if r.fn_name==\"censor\")\n",
    "print(\"matched sends->recvs:\", sum(min(send_pairs[p], recv_pairs.get(p,0)) for p in send_pairs))\n",
    "print(\"total sends:\", len(send_pairs), \"total recvs:\", len(recv_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "822e43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'profanity:get_input_0_1:2->censor:sync:': 107})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "from middleware.serverless_tuner_middleware.critical_path import edge_key\n",
    "\n",
    "with Path(\"results/tts/logs.ndjson\").open() as f:\n",
    "    sends, _ = parse_events_from_lines(f)\n",
    "\n",
    "edges = Counter(edge_key(s) for s in sends if s.from_fn == \"encoding\")\n",
    "print(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f31c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "from middleware.serverless_tuner_middleware.critical_path import edge_key\n",
    "\n",
    "with Path(\"results/tts/logs.ndjson\").open() as f:\n",
    "    sends, _ = parse_events_from_lines(f)\n",
    "\n",
    "by_edge = Counter(edge_key(s) for s in sends)\n",
    "print(by_edge.get(\"encoding:text_2_speech_1_0:3->censor:sync:\"))  # likely 0\n",
    "print(by_edge.get(\"profanity:get_input_0_1:2->censor:sync:\"))      # 107\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f64b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding sends: Counter({'profanity:get_input_0_1:2->censor:sync:': 107})\n",
      "to censor: Counter({'profanity:get_input_0_1:2->censor:sync:': 129})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from middleware.serverless_tuner_middleware.logs import parse_events_from_lines\n",
    "from middleware.serverless_tuner_middleware.critical_path import edge_key\n",
    "\n",
    "with Path(\"results/tts/logs.ndjson\").open() as f:\n",
    "    sends, _ = parse_events_from_lines(f)\n",
    "\n",
    "# All edges emitted by encoding\n",
    "enc_edges = Counter(edge_key(s) for s in sends if s.from_fn == \"encoding\")\n",
    "print(\"encoding sends:\", enc_edges)\n",
    "\n",
    "# All edges to censor (any source)\n",
    "censor_edges = Counter(edge_key(s) for s in sends if s.to_fn == \"censor\")\n",
    "print(\"to censor:\", censor_edges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
